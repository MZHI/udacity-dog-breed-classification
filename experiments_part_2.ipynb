{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and train dog breed classificator from scratch and using transfer learning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, results of the experiments of training and improving the neural network from scratch is presented. In this part experiments 26-51 are described and results are provided.\n",
    "\n",
    "In this series of experiments, the models were improved (in particular, bugs in custom AlexNet and VGG implementations were fixed), and Alexnet batch norm and vgg batch norm (PyTorch's implementation) were trained from scratch and using transfer learning. Go to [models description](#models) for details.\n",
    "\n",
    "Use the links below to navigate between experiments description:\n",
    "\n",
    "* [Experiment 26](#exp26): model `Base`, scratch\n",
    "* [Experiment 27](#exp27): model `Base`, scratch \n",
    "* [Experiment 28](#exp28): model `Base`, scratch \n",
    "* [Experiment 29](#exp29): model `Base`, scratch\n",
    "* [Experiment 30](#exp30): model `Base_2`, scratch \n",
    "* [Experiment 31](#exp31): model `Base_2`, scratch\n",
    "* [Experiment 32](#exp32): model `Base_2`, scratch\n",
    "* [Experiment 33](#exp33): model `AlexNet`, scratch \n",
    "* [Experiment 34](#exp34): model `Base_fix`, scratch \n",
    "* [Experiment 35](#exp35): model `Base_1_fix`, scratch \n",
    "* [Experiment 36](#exp36): model `vgg16`, scratch \n",
    "* [Experiment 37](#exp37): model `vgg16`, scratch \n",
    "* [Experiment 38](#exp38): model `AlexNet` pretrained\n",
    "* [Experiment 39](#exp39): model `AlexNet` pretrained\n",
    "* [Experiment 40](#exp40): model `AlexNet` pretrained\n",
    "* [Experiment 41](#exp41): model `AlexNet`, pretrained\n",
    "* [Experiment 42](#exp42): model `AlexNet` pretrained\n",
    "* [Experiment 43](#exp43): model `vgg16`, pretrained\n",
    "* [Experiment 44](#exp44): model `vgg16`, pretrained \n",
    "* [Experiment 45](#exp45): model `vgg16` pretrained\n",
    "* [Experiment 46](#exp46): model `vgg16_bn`, pretrained\n",
    "* [Experiment 47](#exp47): model `vgg16_bn`, scratch\n",
    "* [Experiment 48](#exp48): model `vgg16_bn`, scratch\n",
    "* [Experiment 49](#exp49): model `vgg16_bn`, scratch\n",
    "* [Experiment 50](#exp50): model `vgg16_bn`, pretrained\n",
    "* [Experiment 51](#exp51): model `vgg16_bn`, scratch\n",
    "\n",
    "\n",
    "[Conclusions](#conclusions) are here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## Models\n",
    "\n",
    "\n",
    "1. `Base`: custom AlexNet realization as in [original paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), but without Local Response Normalization.\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.model_utils import init_model\n",
    "model_base = init_model(\"Base\", 133, pretrained=False)\n",
    "print(model_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. `Base_fix`: same as `Base`, but without sigmoid function after last fully connected layer. Using sigmoid function was a bug/error, which was fixed and tested.\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.model_utils import init_model\n",
    "model_base_fix = init_model(\"Base_fix\", 133, pretrained=False)\n",
    "print(model_base_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `Base_1`: custom AlexNet realization, but more deeper convolution layers (more filters).\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN_v1(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(64, 156, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(156, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_base_1 = init_model(\"Base_1\", 133, pretrained=False)\n",
    "print(model_base_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. `Base_1_fix`: same as Base_1, but without sigmoid function after last fully connected layer. Using sigmoid function was a bug/error, which was fixed and tested.\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN_v1(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(64, 156, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(156, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_base_1_fix = init_model(\"Base_1_fix\", 133, pretrained=False)\n",
    "print(model_base_1_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `AlexNet`: model from torchvision library\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as torch_models\n",
    "model_alexnet = torch_models.alexnet()\n",
    "print(model_alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `vgg16`: model VGG16 from torchvision library\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as torch_models\n",
    "model_vgg16 = torch_models.vgg16()\n",
    "print(model_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments description\n",
    "\n",
    "Fow all experiments, some parameters did'n change:\n",
    "* for SGD momentum value 0.9 was used\n",
    "* for `Base`, `Base_fix`, `Base_1` and `Base_1_fix` for fully connected layers dropout=0.5 was used\n",
    "* a scheduler with following parameters in all experiments was used:\n",
    "  * scheduler patience = 3\n",
    "  * scheduler factor = 0.5\n",
    "  * scheduler cooldown = 2\n",
    "* if Color Jitter was used, the following parameters were used for it:\n",
    "  * brightness = 0.4\n",
    "  * contrast = 0.4\n",
    "  * saturation = 0.4\n",
    "  * hue = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp26'></a>\n",
    "## Experiment 26\n",
    "\n",
    "Details: \n",
    "* model: `Base`\n",
    "* batch size: 32\n",
    "* early stopping: 10\n",
    "* lr: 0.01\n",
    "* weight decay: 0.0005\n",
    "* mean: 0.4864 0.4560 0.3918\n",
    "* std: 0.2602 0.2536 0.2562\n",
    "* augmentation: random horizontal flip, random resized crop and ColorJitter\n",
    "* optimizer: SGD\n",
    "* weight initialization: ones\n",
    "\n",
    "Results:\n",
    "* best epoch: 1\n",
    "* test loss: 4.890350\n",
    "* test accuracy: 0.96% (8/836)\n",
    "* train time (minutes): 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp7'></a>\n",
    "## Experiment 27\n",
    "\n",
    "Parent experiment: [exp 26](#exp26)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* weights initialization: uniform\n",
    "\n",
    "Results:\n",
    "* best epoch: 6\n",
    "* test loss: 5.030281\n",
    "* test accuracy: 0.72% (6/836)\n",
    "* train time (minutes): 2.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp28'></a>\n",
    "## Experiment 28\n",
    "\n",
    "Parent experiment: [exp 26](#exp26)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* weights initialization: general rule\n",
    "\n",
    "Results:\n",
    "* best epoch: 122\n",
    "* test loss: 4.396873\n",
    "* test accuracy: 7.54% (63/836)\n",
    "* train time (minutes): 43.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp29'></a>\n",
    "## Experiment 29\n",
    "\n",
    "Parent experiment: [exp 26](#exp26)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* weights initialization: pytorch default initialization\n",
    "\n",
    "Results:\n",
    "* best epoch: 77\n",
    "* test loss: 4.477621\n",
    "* test accuracy: 5.14% (43/836)\n",
    "* train time (minutes): 119.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp30'></a>\n",
    "## Experiment 30\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> Base_2\n",
    "* augmentaion: no\n",
    "\n",
    "Results:\n",
    "* best epoch: 17\n",
    "* test loss: 3.462288\n",
    "* test accuracy: 16.99% (142/836)\n",
    "* train time (minutes): 8.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp31'></a>\n",
    "## Experiment 31\n",
    "\n",
    "Parent experiment: [exp 30](#exp30)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* ColorJitter: on -> off\n",
    "\n",
    "Results:\n",
    "* best epoch: 109\n",
    "* test loss: 1.588668\n",
    "* test accuracy: 61.24% (512/836)\n",
    "* train time (minutes): 48.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp32'></a>\n",
    "## Experiment 32\n",
    "\n",
    "Parent experiment: [exp 31](#exp31)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* color jitter: off -> on\n",
    "\n",
    "Results:\n",
    "* best epoch: 123\n",
    "* test loss: 1.315878\n",
    "* test accuracy: 66.15% (553/836)\n",
    "* train time (minutes): 192.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp33'></a>\n",
    "## Experiment 33\n",
    "\n",
    "Parent experiment: [exp 32](#exp32)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base_2 -> AlexNet\n",
    "\n",
    "Results:\n",
    "* best epoch: 165\n",
    "* test loss: 1.382329\n",
    "* test accuracy: 66.51% (556/836)\n",
    "* train time (minutes): 262.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp34'></a>\n",
    "## Experiment 34\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> Base_fix\n",
    "\n",
    "Results:\n",
    "* best epoch: 145\n",
    "* test loss: 1.287084\n",
    "* test accuracy: 63.64% (532/836)\n",
    "* train time (minutes): 223.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp35'></a>\n",
    "## Experiment 35\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> Base_1_fix\n",
    "\n",
    "Results:\n",
    "* best epoch: 137\n",
    "* test loss: 1.334149\n",
    "* test accuracy: 64.95% (543/836)\n",
    "* train time (minutes): 214.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp36'></a>\n",
    "## Experiment 36\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> vgg16\n",
    "\n",
    "Results:\n",
    "* best epoch: 99\n",
    "* test loss: 0.943133\n",
    "* test accuracy: 76.56% (640/836)\n",
    "* train time (minutes): 324.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp37'></a>\n",
    "## Experiment 37\n",
    "\n",
    "Parent experiment: [exp 36](#exp36)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* ColorJitter: on -> off\n",
    "\n",
    "Results:\n",
    "* best epoch: 105\n",
    "* test loss: 0.903384\n",
    "* test accuracy: 77.51% (648/836)\n",
    "* train time (minutes): 238.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp38'></a>\n",
    "## Experiment 38\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* pretrained: false -> true\n",
    "* model: Base -> AlexNet\n",
    "* mean: 0.485, 0.456, 0.406\n",
    "* std: 0.229, 0.224, 0.225\n",
    "* number of unfreezed FC layers: 1\n",
    "\n",
    "Results:\n",
    "* best epoch: 75\n",
    "* test loss: 1.022241\n",
    "* test accuracy: 73.56% (615/836)\n",
    "* train time (minutes): 223.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp39'></a>\n",
    "## Experiment 39\n",
    "\n",
    "Parent experiment: [exp 38](#exp38)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* number of unfreezed FC layers: 1 -> 2\n",
    "\n",
    "Results:\n",
    "* best epoch: 81\n",
    "* test loss: 0.990969\n",
    "* test accuracy: 71.65% (599/836)\n",
    "* train time (minutes): 241.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp40'></a>\n",
    "## Experiment 40\n",
    "\n",
    "Parent experiment: [exp 38](#exp38)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* number of unfreezed FC layers: 1 -> 3\n",
    "\n",
    "Results:\n",
    "* best epoch: 90\n",
    "* test loss: 0.986147\n",
    "* test accuracy: 70.45% (589/836)\n",
    "* train time (minutes): 266.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp41'></a>\n",
    "## Experiment 41\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* pretrained model\n",
    "* Model: Base -> AlexNet\n",
    "* augmentation: ColorJitter: true -> false\n",
    "* number of unfreezed FC layers: 3\n",
    "\n",
    "Results:\n",
    "* best epoch: 87\n",
    "* test loss: 0.935989\n",
    "* test accuracy: 74.40% (622/836)\n",
    "* train time (minutes): 68.8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp42'></a>\n",
    "## Experiment 42\n",
    "\n",
    "Parent experiment: [exp 41](#exp41)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* augmentation: horizontal flip: true -> false\n",
    "\n",
    "Results:\n",
    "* best epoch: 92\n",
    "* test loss: 0.971809\n",
    "* test accuracy: 73.33% (613/836)\n",
    "* train time (minutes): 75.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp43'></a>\n",
    "## Experiment 43\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* pretrained: true\n",
    "* model: vgg16\n",
    "* use color jitter: false\n",
    "* use random horizontal flip: false\n",
    "* number of unfreezed FC layers: 1\n",
    "* mean: 0.485, 0.456, 0.406\n",
    "* std: 0.229, 0.224, 0.225\n",
    "* lr: 0.001\n",
    "\n",
    "Results:\n",
    "* best epoch: 36\n",
    "* test loss: 0.360861\n",
    "* test accuracy: 88.88% (613/836)\n",
    "* train time (minutes): 75.72\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp44'></a>\n",
    "## Experiment 44\n",
    "\n",
    "Parent experiment: [exp 43](#exp43)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* number of unfreezed FC layers: 1 -> 2\n",
    "\n",
    "Results:\n",
    "* best epoch: 44\n",
    "* test loss: 0.377006\n",
    "* test accuracy: 89.83% (751/836)\n",
    "* train time (minutes): 86.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp45'></a>\n",
    "## Experiment 45\n",
    "\n",
    "Parent experiment: [exp 43](#exp43)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* number of unfreezed FC layers: 1 -> 3\n",
    "\n",
    "Results:\n",
    "* best epoch: 41\n",
    "* test loss: 0.381830\n",
    "* test accuracy: 88.40% (739/836)\n",
    "* train time (minutes): 60.16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp46'></a>\n",
    "## Experiment 46\n",
    "\n",
    "Parent experiment: [exp 43](#exp43)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: vgg16 -> vgg16_bn\n",
    "* number of unfreezed FC layers: 1\n",
    "\n",
    "Results:\n",
    "* best epoch: 36\n",
    "* test loss: 0.358328\n",
    "* test accuracy: 89.00% (744/836)\n",
    "* train time (minutes): 29.87"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp47'></a>\n",
    "## Experiment 47\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> vgg16_bn\n",
    "* augmentation: use color jitter: false\n",
    "* augmentation: use random horizontal flip: false\n",
    "* mean: 0.485, 0.456, 0.406 (ImageNet)\n",
    "* std: 0.229, 0.224, 0.225 (ImageNet)\n",
    "* * lr: 0.001\n",
    "\n",
    "Results:\n",
    "* best epoch: 105\n",
    "* test loss: 1.872399\n",
    "* test accuracy: 50.00% (418/836)\n",
    "* train time (minutes): 330.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp48'></a>\n",
    "## Experiment 48\n",
    "\n",
    "Parent experiment: [exp 47](#exp47)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* augmentation color jitter: false -> true\n",
    "* lr: 0.001\n",
    "\n",
    "Results:\n",
    "* best epoch: 99\n",
    "* test loss: 1.479383\n",
    "* test accuracy: 58.49% (489/836)\n",
    "* train time (minutes): 320.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp49'></a>\n",
    "## Experiment 49\n",
    "\n",
    "Parent experiment: [exp 48](#exp48)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* augmentation: use random horizontal flip: false -> true\n",
    "\n",
    "Results:\n",
    "* best epoch: 123\n",
    "* test loss: 1.136795\n",
    "* test accuracy: 68.54% (573/836)\n",
    "* train time (minutes): 218.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp50'></a>\n",
    "## Experiment 50\n",
    "\n",
    "Parent experiment: [exp 43](#exp43)\n",
    "\n",
    "Differences from parent experiment: \n",
    "\n",
    "* model: vgg16 -> vgg16_bn\n",
    "* augmentaion: color jitter: false -> true\n",
    "* augmentation: random horizontal flip: false -> true\n",
    "* number of unfreezed FC layers: 1\n",
    "\n",
    "Results:\n",
    "* best epoch: 50\n",
    "* test loss: 0.393089\n",
    "* test accuracy: 88.16% (737/836)\n",
    "* train time (minutes): 88.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp51'></a>\n",
    "## Experiment 51\n",
    "\n",
    "Parent experiment: [exp 49](#exp49)\n",
    "\n",
    "Differences from parent experiment: \n",
    "\n",
    "* mean: 0.4864 0.4560 0.3918 (custom)\n",
    "* std: 0.2602 0.2536 0.2562 (custom)\n",
    "\n",
    "Results:\n",
    "* best epoch: 99\n",
    "* test loss: 0.845104\n",
    "* test accuracy: 75.48% (631/836)\n",
    "* train time (minutes): 167.37"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## CONCLUSIONS for serie of experiments 26-51\n",
    "\n",
    "#### Table with best results for each model  \n",
    "\n",
    "Model | Type(scratch/pretrained) | Test accuracy, % | Test loss | Time, minutes | Experiment | Commentaries\n",
    "----- | ------------------------ | ---------------- | ----------| ------------- | -----------| ------------\n",
    "`Base_fix` | scratch | 63.64 | 1.287084 | 223.72 | [exp 34](#exp34) | -\n",
    "`Base_1_fix` | scratch | 64.95 | 1.334149 | 214.98 | [exp 35](#exp35) | -\n",
    "`Base_2` | scratch | 66.15 | 1.315878 |  192.85 | [exp 32](#exp32) | -\n",
    "`AlexNet` | scratch | 66.51 | 1.382329 | 262.42 | [exp 33](#exp33) | -\n",
    "`AlexNet` | pretrained | 74.40 | 0.935989 | 68.8 | [exp 41](#exp41) | ColorJitter off<br/> horizontal flip on<br/> num unfreezed FC layers: 3\n",
    "`vgg16_bn` | scratch | 75.48 | 0.845104 | 167.37 | [exp 51](#exp51) | ColorJitter on<br/> horizontal flip on<br/> \n",
    "`vgg16` | scratch | 77.51 | 0.903384 | 238.15 | [exp 37](#exp37) | ColorJitter off<br/> horizontal flip on\n",
    "`vgg16_bn` | pretrained | 89.00 | 0.358328 | 29.87 | [exp 46](#exp46) | ColorJitter off<br/> horizontal flip off<br/> num unfreezed FC layers: 1\n",
    "`vgg16` | pretrained | 89.83 | 0.377006 | 86.2 | [exp 44](#exp44) | ColorJitter off<br/> horizontal flip off <br/> num unfreezed FC layers: 2\n",
    "\n",
    "\n",
    "Conclusions:\n",
    "* As usual, more deeper model show better result\n",
    "* For same architecture transfer learning show much better result than training from scratch\n",
    "* `vgg16_bn` show worse result than `vgg16` (it is strange.. why adding batch normalization did't improve result?)\n",
    "* Using batch normalization doing training process faster 2x-3x times both from scratch and using transfer learning\n",
    "* It is better to switch off ColorJitter (and sometimes ever RandomHorizontalFlip) augmentations then using transfer learning mode\n",
    "* For training from scratch using ColorJitter and RandomHorizontalFlip augmentations dramatically improve result\n",
    "* Custom weight initialization technique (so-called \"general rule\") works worse than default weights initialization from PyTorch\n",
    "* It is not clear how much last FC layers unfreeze than using transfer learning (1 or 2 or 3), so, it is better to check all modes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Check [exp 41](#exp41), but with num FC unfreezed = 1 (should improve the result)\n",
    "1. Add more modern architectures and compare results\n",
    "1. Implement and try unfreezing convolution layers"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
