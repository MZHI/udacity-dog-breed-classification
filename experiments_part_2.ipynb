{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write and train dog breed classificator from scratch and using transfer learning\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, results of the experiments of training and improving the neural network from scratch is presented. In this part experiments 26-51 are described and results are provided.\n",
    "\n",
    "In this series of experiments, the models were improved (in particular, bugs in custom AlexNet and VGG implementations were fixed), and Alexnet batch norm and vgg batch norm (PyTorch's implementation) were trained from scratch and using transfer learning. Go to [models description](#models) for details.\n",
    "\n",
    "Use the links below to navigate between experiments description:\n",
    "\n",
    "* [Experiment 26](#exp26): model `Base`\n",
    "* [Experiment 27](#exp27): model `Base` \n",
    "* [Experiment 28](#exp28): model `Base` \n",
    "* [Experiment 29](#exp29): model `Base` \n",
    "* [Experiment 30](#exp30): model `Base` \n",
    "* [Experiment 31](#exp31): model `Base` \n",
    "* [Experiment 32](#exp32): model `Base` \n",
    "* [Experiment 33](#exp33): model `Base` \n",
    "* [Experiment 34](#exp34): model `Base` \n",
    "* [Experiment 35](#exp35): model `Base` \n",
    "* [Experiment 36](#exp36): model `Base` \n",
    "* [Experiment 37](#exp37): model `Base` \n",
    "* [Experiment 38](#exp38): model `AlexNet` (from scratch)\n",
    "* [Experiment 39](#exp39): model `AlexNet` (from scratch)\n",
    "* [Experiment 40](#exp40): model `AlexNet` (from scratch), best result for this model from scratch\n",
    "* [Experiment 41](#exp41): model `Base`, best result for this model\n",
    "* [Experiment 42](#exp42): model `AlexNet` (transfer learning), best result for this model transfer learning\n",
    "* [Experiment 43](#exp43): equal to experiment 17\n",
    "* [Experiment 44](#exp44): model `AlexNet` (transfer learning)\n",
    "* [Experiment 45](#exp45): model `AlexNet` (transfer learning), best result for this model transfer learning\n",
    "* [Experiment 46](#exp46): model `vgg16` (from scratch), best result among all 25 experiments\n",
    "* [Experiment 47](#exp47): model `vgg16` (transfer learning), fail to train\n",
    "* [Experiment 48](#exp48): model `vgg16` (transfer learning), fail to train\n",
    "* [Experiment 49](#exp49): model `vgg16` (transfer learning), fail to train\n",
    "* [Experiment 50](#exp50): model `Base_1` (from scratch), best result for this model from scratch, but worse than model `Base`\n",
    "* [Experiment 51](#exp51): model `Base_1` (from scratch), best result for this model from scratch, but worse than model `Base`\n",
    "\n",
    "\n",
    "[Conclusions](#conclusions) are here.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='models'></a>\n",
    "## Models\n",
    "\n",
    "\n",
    "1. `Base`: custom AlexNet realization as in [original paper](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf), but without Local Response Normalization.\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.model_utils import init_model\n",
    "model_base = init_model(\"Base\", 133, pretrained=False)\n",
    "print(model_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.1. `Base_fix`: same as `Base`, but without sigmoid function after last fully connected layer. Using sigmoid function was a bug/error, which was fixed and tested.\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN(\n",
      "  (conv1): Conv2d(3, 48, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(192, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=4608, out_features=2048, bias=True)\n",
      "  (fc2): Linear(in_features=2048, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from models.model_utils import init_model\n",
    "model_base_fix = init_model(\"Base_fix\", 133, pretrained=False)\n",
    "print(model_base_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. `Base_1`: custom AlexNet realization, but more deeper convolution layers (more filters).\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN_v1(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(64, 156, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(156, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_base_1 = init_model(\"Base_1\", 133, pretrained=False)\n",
    "print(model_base_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.1. `Base_1_fix`: same as Base_1, but without sigmoid function after last fully connected layer. Using sigmoid function was a bug/error, which was fixed and tested.\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicCNN_v1(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "  (conv2): Conv2d(64, 156, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (conv3): Conv2d(156, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv5): Conv2d(256, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6912, out_features=4096, bias=True)\n",
      "  (fc2): Linear(in_features=4096, out_features=2048, bias=True)\n",
      "  (fc3): Linear(in_features=2048, out_features=133, bias=True)\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_base_1_fix = init_model(\"Base_1_fix\", 133, pretrained=False)\n",
    "print(model_base_1_fix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. `AlexNet`: model from torchvision library\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlexNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
      "  (classifier): Sequential(\n",
      "    (0): Dropout(p=0.5, inplace=False)\n",
      "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as torch_models\n",
    "model_alexnet = torch_models.alexnet()\n",
    "print(model_alexnet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. `vgg16`: model VGG16 from torchvision library\n",
    "\n",
    "Model architecture:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as torch_models\n",
    "model_vgg16 = torch_models.vgg16()\n",
    "print(model_vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments description\n",
    "\n",
    "Fow all experiments, some parameters did'n change:\n",
    "* for SGD momentum value 0.9 was used\n",
    "* for `Base`, `Base_fix`, `Base_1` and `Base_1_fix` for fully connected layers dropout=0.5 was used\n",
    "* a scheduler with following parameters in all experiments was used:\n",
    "  * scheduler patience = 3\n",
    "  * scheduler factor = 0.5\n",
    "  * scheduler cooldown = 2\n",
    "* if Color Jitter was used, the following parameters were used for it:\n",
    "  * brightness = 0.4\n",
    "  * contrast = 0.4\n",
    "  * saturation = 0.4\n",
    "  * hue = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp26'></a>\n",
    "## Experiment 26\n",
    "\n",
    "Details: \n",
    "* model: `Base`\n",
    "* batch size: 32\n",
    "* early stopping: 10\n",
    "* lr: 0.01\n",
    "* weight decay: 0.0005\n",
    "* mean: 0.4864 0.4560 0.3918\n",
    "* std: 0.2602 0.2536 0.2562\n",
    "* augmentation: random horizontal flip, random resized crop and ColorJitter\n",
    "* optimizer: SGD\n",
    "* weight initialization: ones\n",
    "\n",
    "Results:\n",
    "* best epoch: 1\n",
    "* test loss: 4.890350\n",
    "* test accuracy: 0.96% (8/836)\n",
    "* train time (minutes): 0.33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp7'></a>\n",
    "## Experiment 27\n",
    "\n",
    "Parent experiment: [exp 26](#exp26)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* weights initialization: uniform\n",
    "\n",
    "Results:\n",
    "* best epoch: 6\n",
    "* test loss: 5.030281\n",
    "* test accuracy: 0.72% (6/836)\n",
    "* train time (minutes): 2.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp28'></a>\n",
    "## Experiment 28\n",
    "\n",
    "Parent experiment: [exp 26](#exp26)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* weights initialization: general rule\n",
    "\n",
    "Results:\n",
    "* best epoch: 122\n",
    "* test loss: 4.396873\n",
    "* test accuracy: 7.54% (63/836)\n",
    "* train time (minutes): 43.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp29'></a>\n",
    "## Experiment 29\n",
    "\n",
    "Parent experiment: [exp 26](#exp26)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* weights initialization: pytorch default initialization\n",
    "\n",
    "Results:\n",
    "* best epoch: 77\n",
    "* test loss: 4.477621\n",
    "* test accuracy: 5.14% (43/836)\n",
    "* train time (minutes): 119.08"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp30'></a>\n",
    "## Experiment 30\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> Base_2\n",
    "* augmentaion: no\n",
    "\n",
    "Results:\n",
    "* best epoch: 17\n",
    "* test loss: 3.462288\n",
    "* test accuracy: 16.99% (142/836)\n",
    "* train time (minutes): 8.68"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp31'></a>\n",
    "## Experiment 31\n",
    "\n",
    "Parent experiment: [exp 30](#exp30)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* ColorJitter: on -> off\n",
    "\n",
    "Results:\n",
    "* best epoch: 109\n",
    "* test loss: 1.588668\n",
    "* test accuracy: 61.24% (512/836)\n",
    "* train time (minutes): 48.93"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp32'></a>\n",
    "## Experiment 32\n",
    "\n",
    "Parent experiment: [exp 31](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* color jitter: off -> on\n",
    "\n",
    "Results:\n",
    "* best epoch: 123\n",
    "* test loss: 1.315878\n",
    "* test accuracy: 66.15% (553/836)\n",
    "* train time (minutes): 192.85"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp33'></a>\n",
    "## Experiment 33\n",
    "\n",
    "Parent experiment: [exp 32](#exp32)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base_2 -> AlexNet\n",
    "\n",
    "Results:\n",
    "* best epoch: 165\n",
    "* test loss: 1.382329\n",
    "* test accuracy: 66.51% (556/836)\n",
    "* train time (minutes): 262.42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp34'></a>\n",
    "## Experiment 34\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> Base_fix\n",
    "\n",
    "Results:\n",
    "* best epoch: 145\n",
    "* test loss: 1.287084\n",
    "* test accuracy: 63.64% (532/836)\n",
    "* train time (minutes): 223.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp35'></a>\n",
    "## Experiment 35\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> Base_1_fix\n",
    "\n",
    "Results:\n",
    "* best epoch: 137\n",
    "* test loss: 1.334149\n",
    "* test accuracy: 64.95% (543/836)\n",
    "* train time (minutes): 214.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp36'></a>\n",
    "## Experiment 36\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* model: Base -> vgg16\n",
    "\n",
    "Results:\n",
    "* best epoch: 99\n",
    "* test loss: 0.943133\n",
    "* test accuracy: 76.56% (640/836)\n",
    "* train time (minutes): 324.48"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp37'></a>\n",
    "## Experiment 37\n",
    "\n",
    "Parent experiment: [exp 36](#exp36)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* ColorJitter: on -> off\n",
    "\n",
    "Results:\n",
    "* best epoch: 105\n",
    "* test loss: 0.903384\n",
    "* test accuracy: 77.51% (648/836)\n",
    "* train time (minutes): 238.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp38'></a>\n",
    "## Experiment 38\n",
    "\n",
    "Parent experiment: [exp 29](#exp29)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* pretrained: false -> true\n",
    "* model: Base -> AlexNet\n",
    "* mean: 0.485, 0.456, 0.406\n",
    "* std: 0.229, 0.224, 0.225\n",
    "* number of unfreezed layers: 1\n",
    "\n",
    "Results:\n",
    "* best epoch: 75\n",
    "* test loss: 1.022241\n",
    "* test accuracy: 73.56% (615/836)\n",
    "* train time (minutes): 223.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp39'></a>\n",
    "## Experiment 39\n",
    "\n",
    "Parent experiment: [exp 38](#exp38)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* number of unfreezed FC layers: 1 -> 2\n",
    "\n",
    "Results:\n",
    "* best epoch: 81\n",
    "* test loss: 0.990969\n",
    "* test accuracy: 71.65% (599/836)\n",
    "* train time (minutes): 241.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp40'></a>\n",
    "## Experiment 40\n",
    "\n",
    "Parent experiment: [exp 38](#exp38)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* number of unfreezed FC layers: 1 -> 3\n",
    "\n",
    "Results:\n",
    "* best epoch: 17\n",
    "* test loss: 3.64\n",
    "* test accuracy: 13.88% (116/836)\n",
    "* train time (minutes): 9.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp16'></a>\n",
    "## Experiment 16\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* use mean and std for current train dataset\n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "\n",
    "Results:\n",
    "* best epoch: 144\n",
    "* test loss: 4.382009\n",
    "* test accuracy: 7.89% (66/836)\n",
    "* train time (minutes): 51.76"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp17'></a>\n",
    "## Experiment 17\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> AlexNet \n",
    "* use pretrained weights, unfreeze last FC layer\n",
    "\n",
    "\n",
    "Results:\n",
    "* best epoch: 42\n",
    "* test loss: 1.062519\n",
    "* test accuracy: 74.88% (626/836)\n",
    "* train time (minutes): 17.32"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp18'></a>\n",
    "## Experiment 18\n",
    "\n",
    "equal to [exp 17](#exp17)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp19'></a>\n",
    "## Experiment 19\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> AlexNet \n",
    "* use pretrained weights, unfreeze last 2 FC layers\n",
    "\n",
    "Results:\n",
    "* best epoch: 53\n",
    "* test loss: 1.061143\n",
    "* test accuracy: 72.13% (603/836)\n",
    "* train time (minutes): 22.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp20'></a>\n",
    "## Experiment 20\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> AlexNet \n",
    "* use pretrained weights, unfreeze last 3 FC layers\n",
    "\n",
    "Results:\n",
    "* best epoch: 42\n",
    "* test loss: 1.062519\n",
    "* test accuracy: 74.88% (626/836)\n",
    "* train time (minutes): 18.58"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp21'></a>\n",
    "## Experiment 21\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* use mean and std for current train dataset\n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> vgg16 (from scratch)\n",
    "\n",
    "Results:\n",
    "* best epoch: 110\n",
    "* test loss: 0.992273\n",
    "* test accuracy: 76.44% (639/836)\n",
    "* train time (minutes): 248.18"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp22'></a>\n",
    "## Experiment 22\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> vgg16 \n",
    "* use pretrained weights, unfreeze last FC layer\n",
    "\n",
    "Results:\n",
    "* best epoch: 1\n",
    "* test loss: 2.082360\n",
    "* test accuracy: 52.63% (440/836)\n",
    "* train time (minutes): 2.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp23'></a>\n",
    "## Experiment 23\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> vgg16 \n",
    "* use pretrained weights, unfreeze last 2 FC layers\n",
    "\n",
    "Results:\n",
    "* best epoch: 1\n",
    "* test loss: 2.082360\n",
    "* test accuracy: 52.63% (440/836)\n",
    "* train time (minutes): 1.47"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp24'></a>\n",
    "## Experiment 24\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> vgg16 \n",
    "* use pretrained weights, unfreeze last 3 FC layers\n",
    "\n",
    "Results:\n",
    "* best epoch: 1\n",
    "* test loss: 2.082360\n",
    "* test accuracy: 52.63% (440/836)\n",
    "* train time (minutes): 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exp25'></a>\n",
    "## Experiment 25\n",
    "\n",
    "Parent experiment: [exp 1](#exp1)\n",
    "\n",
    "Differences from parent experiment: \n",
    "* use mean and std for current train dataset\n",
    "* add weight decay 0.0005\n",
    "* add augmentaion: RandomHorizontalFlip and RandomResizedCrop\n",
    "* add augmentation: Color Jitter\n",
    "* model: Base -> Base_1 (from scratch)\n",
    "\n",
    "Results:\n",
    "* best epoch: 124\n",
    "* test loss: 4.401157\n",
    "* test accuracy: 5.26% (44/836)\n",
    "* train time (minutes): 47.38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='conclusions'></a>\n",
    "## CONCLUSIONS for series of experiments 1-25\n",
    "\n",
    "Which improvements have been made:\n",
    "* For `Base` model:\n",
    "  * optimizer SGD works faster than Adam and a little better. [exp 1](#exp1) vs [exp 6](#exp6)\n",
    "  * if using Adam, it is better to start with small values of learning rate (0.00001). [exp 6](#exp6) vs [exp 5](#exp5) \n",
    "  * it is better to calculate actual mean and std from train split than use imagenet values (for training model from scratch) [exp 10](#exp10) vs [exp 9](#exp9)\n",
    "  * using weight decay 0.00005 get better result than not using. [exp 11](#exp11) vs [exp 10](#exp10)\n",
    "  * using Horizontal Flip and Random Resized Crop augmentation reduce overfitting and get better result: [exp 12](#exp12) vs [exp 11](#exp11)\n",
    "  * adding augmentations from ColorJitter get some enhancements: [exp 16](#exp16) vs [exp 12](#exp12)\n",
    "* Using `AlexNet` (from torchvision) model get 10x better result than my custom `Base`, if train from scratch: [exp 13](#exp13) vs [exp 12](#exp12)\n",
    "* Using transfer learning for `AlexNet` get some better result than train from scratch and ~5x time faster training: [exp 17](#exp17) vs [exp 15](#exp15)\n",
    "* Using vgg16 from scratch get small better result than AlexNet transfer learning: [exp 21](#exp21) vs [exp 17](#exp17)\n",
    "* but transfer learning for vgg failed [exp 22](#exp21), [exp 23](#exp23), [exp 24](#exp24). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What's next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Explore why vgg transfer learning failed\n",
    "2. Explore why my custom AlexNet realization 10x worse than PyTorch (may be key in adaptive average pool?)\n",
    "3. Check transfer learning with unfreezing convolution layers too (in these experiments fully connected layer were unfreezed only)\n",
    "4. Try state of the art architectures to train (from scratch and transfer learning)\n",
    "5. Get 90% of test accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
